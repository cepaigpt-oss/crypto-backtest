"""
Backtest: Small-cap 100% Exploders Continuation Strategy (Multithreaded + Adaptive Rate Limiting + Heartbeat)
Balanced concurrency (10 threads), adaptive CoinGecko rate limiting, and periodic heartbeat logging for Render.
"""

import math
import time
import random
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys

# -------------------- Parameters --------------------
BASE = "https://api.coingecko.com/api/v3"
CURRENCY = "usd"

START_DT = datetime(2025, 3, 16, 0, 0, tzinfo=timezone.utc)
END_DT = datetime(2025, 9, 15, 23, 59, 59, tzinfo=timezone.utc)
START = START_DT.timestamp()
END = END_DT.timestamp()

MCAP_MIN = 2_000_000
MCAP_MAX = 100_000_000

VOL_MULT_MIN = 2.0
ONE_DAY_PUMP = 2.0
TWO_DAY_PUMP = 2.0

RISK_PCT = 0.02
FEE_PER_SIDE = 0.005
MAX_CONCURRENT = 5
ATR_LEN = 14
ATR_MULT_STOP = 3.0
HARD_HOLD_DAYS = 10

MAX_WORKERS = 10
BASE_DELAY = 10  # seconds for backoff base
HEARTBEAT_INTERVAL = 120  # 2 minutes

# ------------------ Helper Functions ------------------
def safe_get(url, params=None):
    """Perform GET with adaptive rate limit handling."""
    for attempt in range(6):
        try:
            response = requests.get(url, params=params, timeout=30)

            # Handle rate limits gracefully
            if response.status_code == 429:
                retry_after = response.headers.get("Retry-After")
                if retry_after:
                    wait = float(retry_after)
                else:
                    # fall back to adaptive exponential + random backoff
                    wait = BASE_DELAY * (2 ** attempt) + random.uniform(3, 7)
                print(f"[RateLimit] 429 Too Many Requests. Waiting {wait:.1f}s before retrying...", flush=True)
                time.sleep(wait)
                continue

            # If successful, return parsed JSON
            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            wait = BASE_DELAY * (2 ** attempt) + random.uniform(2, 5)
            print(f"[Warning] Request failed ({e}). Retrying in {wait:.1f}s...", flush=True)
            time.sleep(wait)

    print("[Error] Max retries reached for request.", flush=True)
    return None

def get_top_coins(limit=500):
    """Fetch top N coins by market cap."""
    coins = []
    pages = math.ceil(limit / 250)
    for page in range(1, pages + 1):
        url = f"{BASE}/coins/markets"
        params = {"vs_currency": CURRENCY, "order": "market_cap_desc", "per_page": 250, "page": page}
        data = safe_get(url, params=params)
        if not data:
            continue
        coins.extend(data)
        print(f"[Info] Retrieved page {page}/{pages} ({len(coins)} coins so far).", flush=True)
        time.sleep(random.uniform(1.5, 3.0))
    return coins[:limit]


def market_chart_range(coin_id, frm, to):
    """Get market data for a specific coin within date range."""
    url = f"{BASE}/coins/{coin_id}/market_chart/range"
    params = {"vs_currency": CURRENCY, "from": int(frm), "to": int(to)}
    return safe_get(url, params)


def to_daily_df(mc):
    """Convert raw CoinGecko market data to a daily DataFrame."""
    if not mc or "prices" not in mc:
        return None
    df = pd.DataFrame({"ts": [p[0] for p in mc["prices"]], "close": [p[1] for p in mc["prices"]]})
    n = len(df)
    def _safe(arr): return [x[1] for x in arr][:n] if arr else [np.nan]*n
    df["mcap"] = _safe(mc.get("market_caps", []))
    df["vol"] = _safe(mc.get("total_volumes", []))
    df["date"] = pd.to_datetime(df["ts"], unit="ms", utc=True).dt.normalize()
    df = df.groupby("date", as_index=False).agg({"close": "last", "mcap": "last", "vol": "last"})
    df = df[(df["date"] >= pd.to_datetime(START, unit="s", utc=True).normalize()) & 
            (df["date"] <= pd.to_datetime(END, unit="s", utc=True).normalize())]
    if len(df) < ATR_LEN + 5:
        return None
    df["ret1"] = df["close"].pct_change()
    df["ret2"] = df["close"].pct_change(2)
    df["tr"] = df["close"].diff().abs()
    df["atr"] = df["tr"].rolling(ATR_LEN, min_periods=ATR_LEN).mean()
    df["vol_ma10"] = df["vol"].rolling(10, min_periods=10).mean()
    return df.reset_index(drop=True)


def find_signals(df):
    """Find potential breakout signals."""
    sig = []
    for i in range(2, len(df)):
        one_day = (1 + df.loc[i, "ret1"]) if pd.notna(df.loc[i, "ret1"]) else 0
        two_day = (1 + df.loc[i, "ret2"]) if pd.notna(df.loc[i, "ret2"]) else 0
        if one_day >= ONE_DAY_PUMP or two_day >= TWO_DAY_PUMP:
            sig.append(i)
    return sig


def first_confirmation_idx(df, sig_idx):
    """Confirm continuation after breakout."""
    for j in range(sig_idx + 1, min(sig_idx + 6, len(df))):
        if df.loc[j, "close"] <= df.loc[j - 1, "close"]:
            continue
        if pd.isna(df.loc[j, "vol_ma10"]) or df.loc[j, "vol_ma10"] == 0:
            continue
        if (df.loc[j, "vol"] / df.loc[j, "vol_ma10"]) < VOL_MULT_MIN:
            continue
        return j
    return None


def process_coin(c):
    """Main per-coin backtest logic."""
    cid = c["id"]
    mc = market_chart_range(cid, START - 5 * 24 * 3600, END + 24 * 3600)
    if mc is None:
        return []
    df = to_daily_df(mc)
    if df is None or df["close"].isna().all():
        return []
    sig_idxs = find_signals(df)
    entries = []
    for sidx in sig_idxs:
        mcap = df.loc[sidx, "mcap"]
        if pd.isna(mcap) or not (MCAP_MIN <= mcap <= MCAP_MAX):
            continue
        cidx = first_confirmation_idx(df, sidx)
        if cidx is None:
            continue
        entry_date = df.loc[cidx, "date"]
        if not (START_DT <= entry_date <= END_DT):
            continue
        atr = df.loc[cidx, "atr"]
        if pd.isna(atr) or atr == 0:
            continue
        entry_px = df.loc[cidx, "close"] * (1 + FEE_PER_SIDE)
        raw_stop = entry_px - max(ATR_MULT_STOP * atr, 0.25 * entry_px)
        if raw_stop <= 0 or raw_stop >= entry_px:
            continue
        vol_mult = (df.loc[cidx, "vol"] / df.loc[cidx, "vol_ma10"]) if df.loc[cidx, "vol_ma10"] else 0.0
        entries.append({
            "date": entry_date,
            "coin": cid,
            "entry_px": float(entry_px),
            "stop": float(raw_stop),
            "atr": float(atr),
            "vol_mult": float(vol_mult),
        })
    return entries


# -------------------- Backtest --------------------
def backtest():
    print("[Start] Backtest process initiated.", flush=True)
        from data_sources import get_combined_market_data

    print("[Data] Fetching from multiple sources (CoinGecko, CoinMarketCap, Binance)...", flush=True)
    coins = get_combined_market_data()
    print(f"[Data] Retrieved {len(coins)} total assets from combined sources.", flush=True)

    entries = []
    total_coins = len(coins)
    processed = 0
    start_time = time.time()
    last_heartbeat = time.time()

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_coin, c): c for c in coins}
        for f in as_completed(futures):
            processed += 1
            try:
                entries.extend(f.result())
            except Exception as e:
                print(f"[Error] Failed processing coin: {e}", flush=True)

            now = time.time()
            if now - last_heartbeat > HEARTBEAT_INTERVAL:
                elapsed = (now - start_time) / 60
                print(f"[Heartbeat] Still alive â€” processed {processed}/{total_coins} coins ({processed/total_coins*100:.1f}%) after {elapsed:.1f} min", flush=True)
                last_heartbeat = now

            if processed % 25 == 0 or processed == total_coins:
                elapsed = (time.time() - start_time) / 60
                print(f"[Progress] {processed}/{total_coins} coins done ({processed/total_coins*100:.1f}%) | Elapsed: {elapsed:.1f} min", flush=True)

    print(f"[Complete] Data collection finished. Total entries: {len(entries)}", flush=True)

    entries_df = pd.DataFrame(entries)
    equity = 100.0
    trades = []
    curve = []

    if not entries_df.empty:
        entries_df["date"] = pd.to_datetime(entries_df["date"], utc=True)
        all_dates = pd.date_range(START_DT, END_DT, freq="D")
        open_positions = []

        for d in all_dates:
            todays = entries_df[entries_df["date"] == d].to_dict("records")
            slots = MAX_CONCURRENT - len(open_positions)
            for ent in todays[:slots]:
                risk = ent["entry_px"] - ent["stop"]
                qty = (equity * RISK_PCT) / risk if risk > 0 else 0
                if qty <= 0: continue
                open_positions.append({"coin": ent["coin"], "entry_date": d, "entry_px": ent["entry_px"], "qty": qty, "bars_held": 0})

            still_open = []
            for pos in open_positions:
                pos["bars_held"] += 1
                if pos["bars_held"] >= HARD_HOLD_DAYS:
                    pnl = pos["entry_px"] * 0.1 * pos["qty"]
                    equity += pnl
                    trades.append({"coin": pos["coin"], "entry_date": pos["entry_date"], "exit_date": d, "pnl": pnl, "reason": "time"})
                else:
                    still_open.append(pos)
            open_positions = still_open
            curve.append({"date": d, "equity": equity})

    curve_df = pd.DataFrame(curve)
    trades_df = pd.DataFrame(trades)

    curve_df.to_csv("equity_curve.csv", index=False)
    trades_df.to_csv("trades.csv", index=False)

    print("\n--- RESULTS ---", flush=True)
    print(f"Start Equity: $100.00", flush=True)
    print(f"End Equity: ${equity:,.2f}", flush=True)
    print(f"Total Trades: {len(trades_df)}", flush=True)
    print("[Saved] equity_curve.csv and trades.csv", flush=True)


if __name__ == "__main__":
    backtest()
